{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Clickbait Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Team members: Joshua Burris, Caleb Tong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import string\n",
    "from collections import Counter\n",
    "class language_model:\n",
    "    def __init__(self, ngram=1) :\n",
    "        \"\"\"\n",
    "        Initialize a language model\n",
    "        \n",
    "        Parameters:\n",
    "        ngram specifies the type of model:  \n",
    "        unigram (ngram = 1), bigram (ngram = 2) etc.\n",
    "        \"\"\"\n",
    "        self.ngram = ngram\n",
    "        \n",
    "    def train(self, file_name) :\n",
    "        self.story = self.clean_text(file_name)\n",
    "        if self.ngram > 1:\n",
    "            self.bigram = []\n",
    "            for i in range(len(self.story) - 1):\n",
    "                self.bigram.append(self.story[i] + ' ' + self.story[i+1])\n",
    "            self.bigram = Counter(self.bigram)\n",
    "        if self.ngram > 2:\n",
    "            self.trigram = []\n",
    "            for i in range(len(self.story) - self.ngram + 1):\n",
    "                temp = self.story[i]\n",
    "                for j in range(1, self.ngram):\n",
    "                    temp += ' ' + self.story[i+j]\n",
    "                self.trigram.append(temp)\n",
    "            self.trigram = Counter(self.trigram)\n",
    "        self.data_frequency = Counter(self.story)\n",
    "        self.V = len(self.data_frequency)\n",
    "        self.total_count = sum(self.data_frequency.values())\n",
    "        #print(self.total_count, self.V, self.data_frequency)\n",
    "    \n",
    "    def test(self, file_name) :\n",
    "        text = self.clean_text(file_name)\n",
    "        \n",
    "        non_entries, entries = 0, 0\n",
    "        for i in range(len(text) - self.ngram + 1):\n",
    "            temp = text[i]\n",
    "            for j in range(1, self.ngram):\n",
    "                temp += ' ' + text[i+j]\n",
    "            data = {}\n",
    "            if self.ngram == 1:\n",
    "                data = self.data_frequency\n",
    "            elif self.ngram == 2:\n",
    "                data = self.bigram\n",
    "            elif self.ngram == 3:\n",
    "                data = self.trigram\n",
    "            if data.setdefault(temp, 0) == 0:\n",
    "                non_entries += 1\n",
    "            entries += 1\n",
    "        \n",
    "        self.sparsity = non_entries / entries\n",
    "        \n",
    "        return self.perplexity(text)\n",
    "    \n",
    "    def probability(self, word1, words):\n",
    "        if self.ngram == 1:\n",
    "            return (self.C([word1]) + 1) / (self.total_count + self.V)\n",
    "        else:\n",
    "            return (self.C(words + [word1]) + 1) / (self.C(words) + self.V)\n",
    "    \n",
    "    def perplexity(self, text):\n",
    "        return math.pow(2, self.entropy(text))\n",
    "    \n",
    "    def entropy(self, text):\n",
    "        exp = 0\n",
    "        for i in range(self.ngram - 1, len(text)) :\n",
    "            prevW = text[i - self.ngram + 1 : i]\n",
    "            exp += -math.log(self.probability(text[i], prevW), 2)     \n",
    "        return exp / (len(text) - (self.ngram - 1))\n",
    "    \n",
    "    def C(self, words):\n",
    "        size = len(words)\n",
    "        words = ' '.join(words)\n",
    "        if size == 1: return self.data_frequency.setdefault(words, 0)\n",
    "        if size == 2: return self.bigram.setdefault(words, 0)\n",
    "        if size == 3: return self.trigram.setdefault(words, 0)\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def clean_text(self, file_name):\n",
    "        result = []\n",
    "        if file_name[-4:] == '.txt':\n",
    "            with open(file_name, 'r') as f:\n",
    "                text = f.read()\n",
    "                text = text.lower()\n",
    "                result = []\n",
    "                trantab = str.maketrans(\"?:!-\", \"... \")\n",
    "                text = text.translate(trantab)\n",
    "                trantab = str.maketrans('', '', string.punctuation.replace('.', ''))\n",
    "                text = text.translate(trantab)\n",
    "                text = text.replace('\\n\\n', '.')\n",
    "                tokens = text.split('.')\n",
    "                for token in tokens:\n",
    "                    result += ['<s>'] + token.split() + [' </s>']\n",
    "        else:\n",
    "            result = [\"<s>\"] + file_name.lower().split() + [\"</s>\"]\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def language_m(textFiles):\n",
    "    model = language_model(3)\n",
    "    model.train(textFiles)\n",
    "    print('Train:', textFiles)\n",
    "    print('Perplexity:', model.test(textFiles), '\\t(on Test:' + textFiles + ')')\n",
    "    #print(model.story)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(sentence, origin):\n",
    "    return sentence in origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "def runLM(dataFiles):\n",
    "    print(\"\\n<TRAIN>\\n\")\n",
    "    cLM = language_m(dataFiles[0])\n",
    "    ncLM = language_m(dataFiles[1])\n",
    "    print(\"\\n</TRAIN>\\n\")\n",
    "    with open(dataFiles[2], 'r') as file:\n",
    "        c_titles = file.read().split('\\n\\n')\n",
    "    with open(dataFiles[3], 'r') as file:\n",
    "        nc_titles = file.read().split('\\n\\n')\n",
    "    \n",
    "    titles = c_titles + nc_titles\n",
    "    random.shuffle(titles)\n",
    "    length = len(titles)\n",
    "    i, num = 0, 0\n",
    "    print(\"\\n<TEST>\\n\")\n",
    "    while i < 20:\n",
    "        index = random.randint(0, length-1)\n",
    "        sentence = titles[index]\n",
    "        c_perp = cLM.test(sentence)\n",
    "        nc_perp = ncLM.test(sentence)\n",
    "        #print(c_perp, nc_perp, nc_perp-c_perp, nc_perp//2, abs((nc_perp-c_perp) - nc_perp//2))\n",
    "        \n",
    "        \n",
    "        ##TODO:Find the perplexity cutting off point substitute 3000 with that value or just change the condition\n",
    "        if c_perp < nc_perp and abs((nc_perp-c_perp) - nc_perp//2) < 3000:\n",
    "            print(\"Evaluation: CLICKBAIT, Check: \" + str(check(sentence, c_titles)) + \n",
    "                  \"\\n\\t\\tTitle: \\\"\" + sentence + \"\\\"\" )#+ \" Perp: \" + str(abs((nc_perp-c_perp) - nc_perp//2)))\n",
    "            if check(sentence, c_titles):\n",
    "                num+=1\n",
    "        else:\n",
    "            print(\"Evaluation: NOT CLICKBAIT, Check: \" + str(check(sentence, nc_titles)) + \n",
    "                  \"\\n\\t\\tTitle: \\\"\" + sentence + \"\\\"\" )#+ \" Perp: \" + str(abs((nc_perp-c_perp) - nc_perp//2)))\n",
    "            if check(sentence, c_titles):\n",
    "                num+=1\n",
    "        i += 1\n",
    "    print(\"Accuracy:\", num*5, \"%\")\n",
    "    print(\"\\n</TEST>\\n\")\n",
    "    while True:\n",
    "        sentence = input(\"Enter a sentence to predict whether it is clickbait or not ('stop' for stopping) : \\n\")\n",
    "\n",
    "        if sentence == \"stop\":\n",
    "            break;\n",
    "        c_perp = cLM.test(sentence)\n",
    "        nc_perp = ncLM.test(sentence)\n",
    "        ##\n",
    "        if c_perp < nc_perp and abs((nc_perp-c_perp) - nc_perp//2) < 3000:\n",
    "            print(\"\\nEvaluation for title:\\n\\\"\" + sentence + \"\\\"-> CLICKBAIT\\n\")\n",
    "        else:\n",
    "            print(\"\\nEvaluation for title:\\n\\\"\" + sentence + \"\\\"-> NOT CLICKBAIT\\n\")\n",
    "        print(\"\\n\" + \"____________________\" + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<TRAIN>\n",
      "\n",
      "Train: train/clickbait_data1.txt\n",
      "Perplexity: 2156.956516117808 \t(on Test:train/clickbait_data1.txt)\n",
      "Train: train/non_clickbait_data1.txt\n",
      "Perplexity: 4913.472183920156 \t(on Test:train/non_clickbait_data1.txt)\n",
      "\n",
      "</TRAIN>\n",
      "\n",
      "\n",
      "<TEST>\n",
      "\n",
      "Evaluation: NOT CLICKBAIT, Check: True\n",
      "\t\tTitle: \"Palestinian security forces clash with militants, Palestinian Interrior Minister Nasser Yousef declares state of emergency\"\n",
      "Evaluation: NOT CLICKBAIT, Check: True\n",
      "\t\tTitle: \"UK retailers MFI and Woolworths collapse\"\n",
      "Evaluation: NOT CLICKBAIT, Check: True\n",
      "\t\tTitle: \"AFC Asian Cup: Thailand defeat Oman, Qatar draw with Vietnam\"\n",
      "Evaluation: NOT CLICKBAIT, Check: False\n",
      "\t\tTitle: \"Tell Us About Yourself(ie): Ta'Rhonda Jones\"\n",
      "Evaluation: CLICKBAIT, Check: True\n",
      "\t\tTitle: \"I Cooked With An Easy-Bake Oven For A Week And Here's What Happened\"\n",
      "Evaluation: CLICKBAIT, Check: True\n",
      "\t\tTitle: \"18 Reasons Why Ellie Goulding Is The Luckiest Girl On Earth\"\n",
      "Evaluation: NOT CLICKBAIT, Check: True\n",
      "\t\tTitle: \"England; Australia set to battle for right to host 2018 Football (Soccer) World Cup while U.S. are considering their options\"\n",
      "Evaluation: CLICKBAIT, Check: True\n",
      "\t\tTitle: \"The 11 Best Red Hot Chili Peppers Songs Of All Time\"\n",
      "Evaluation: NOT CLICKBAIT, Check: False\n",
      "\t\tTitle: \"This Is The Hardest \"Divergent\" Quiz You'll Ever Take\"\n",
      "Evaluation: NOT CLICKBAIT, Check: False\n",
      "\t\tTitle: \"Can You Identify The Rihanna Music Video By A Single Screenshot\"\n",
      "Evaluation: NOT CLICKBAIT, Check: False\n",
      "\t\tTitle: \"Here's Why Halloween On \"Scream Queens\" Rules\"\n",
      "Evaluation: CLICKBAIT, Check: True\n",
      "\t\tTitle: \"These Kittens Got Together For The Cutest Playtime Ever\"\n",
      "Evaluation: NOT CLICKBAIT, Check: False\n",
      "\t\tTitle: \"Can You Get Through This Post Without Becoming Sexually Attracted To Cheese\"\n",
      "Evaluation: NOT CLICKBAIT, Check: False\n",
      "\t\tTitle: \"Psst, Free Idea: Let's Stop Sexualising Underage Bollywood Kids\"\n",
      "Evaluation: NOT CLICKBAIT, Check: False\n",
      "\t\tTitle: \"How Well Do You Remember \"That's So Raven\"\"\n",
      "Evaluation: CLICKBAIT, Check: True\n",
      "\t\tTitle: \"12 Charts Only Sephora Lovers Will Understand\"\n",
      "Evaluation: NOT CLICKBAIT, Check: False\n",
      "\t\tTitle: \"Can You Identify These Meryl Streep Movies By Their Amazon Reviews\"\n",
      "Evaluation: NOT CLICKBAIT, Check: True\n",
      "\t\tTitle: \"Space Shuttle Endeavour lands in California\"\n",
      "Evaluation: NOT CLICKBAIT, Check: True\n",
      "\t\tTitle: \"Tensions Rise on Korean Peninsula\"\n",
      "Evaluation: CLICKBAIT, Check: True\n",
      "\t\tTitle: \"23 Times Andy Dwyer From \"Parks & Rec\" Was Wrong About Everything\"\n",
      "Accuracy: 70 %\n",
      "\n",
      "</TEST>\n",
      "\n",
      "Enter a sentence to predict whether it is clickbait or not ('stop' for stopping) : \n",
      "Brexit Is Going to Get Done. But on Whose Terms?\n",
      "\n",
      "Evaluation for title:\n",
      "\"Brexit Is Going to Get Done. But on Whose Terms?\"-> CLICKBAIT\n",
      "\n",
      "\n",
      "____________________\n",
      "\n",
      "Enter a sentence to predict whether it is clickbait or not ('stop' for stopping) : \n",
      "Boy, 13, Arrested in Fatal Stabbing of Tessa Majors, Barnard Freshman\n",
      "\n",
      "Evaluation for title:\n",
      "\"Boy, 13, Arrested in Fatal Stabbing of Tessa Majors, Barnard Freshman\"-> NOT CLICKBAIT\n",
      "\n",
      "\n",
      "____________________\n",
      "\n",
      "Enter a sentence to predict whether it is clickbait or not ('stop' for stopping) : \n",
      "Panel Approves Impeachment Articles and Sends Charges for a House Vote\n",
      "\n",
      "Evaluation for title:\n",
      "\"Panel Approves Impeachment Articles and Sends Charges for a House Vote\"-> NOT CLICKBAIT\n",
      "\n",
      "\n",
      "____________________\n",
      "\n",
      "Enter a sentence to predict whether it is clickbait or not ('stop' for stopping) : \n",
      "stop\n"
     ]
    }
   ],
   "source": [
    "dataFiles = [\"train/clickbait_data1.txt\", \"train/non_clickbait_data1.txt\", \"test/clickbait_data2.txt\", \"test/non_clickbait_data2.txt\"]\n",
    "\n",
    "runLM(dataFiles)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

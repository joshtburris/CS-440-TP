{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 440 Final Project: Clickbait Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Team members: Joshua Burris, Caleb Tong"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "The number of clickbait advertisement on the internet that has risen dramatically for the past few years is becoming a problem. Thus, we decided to conduct an experiment on clickbait detection based using a Language model (instead of a more commonly used Naive Bayes model). \n",
    "\n",
    "The reason for this methodology includes that we are more familiar with using the language model, but also we are curious about the results. Normally speaking, the Naive Bayes model is used for categorising / classification of a sentence or an input. Language models on the other hand are used for prediction for the next best word to continue the sentence. But the question remain, since language model is more powerful, can it do what Naive Bayes do, just as well?\n",
    "\n",
    "The code below is the experiment we decided to conduct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition of Clickbait\n",
    "\n",
    "As we proceed to con duct the experiment, do take note that our classification of what is and what is not clickbait, is based on how interesting it sounds. As such it does not only include titles that are false news or titles of advertisements that doesn't exist but are just there to redirect the user to another website (not what was advertised), etc, but it also includes that which are real news, but really intrigues the user. \n",
    "\n",
    "Formally, we define clickbait as:\n",
    "\n",
    "<b> Content on the internet whose main purpose is to attract attention and encourage visitors to click on a link to a particular web page. </b>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we created the language model class that is similar to what we did in our class assignment in CS440. This class allows us to train a model given a dataset of clickbait titles, a dataset of nonclickbait titles, and test the model on another (exclusive) dataset of clickbait titles and that of nonclickbait titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "testing_mode = False\n",
    "argv = ['train/train_clickbait.txt', 'test/test_clickbait.txt', 'train/train_nonclickbait.txt', 'test/test_nonclickbait.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, string\n",
    "from collections import Counter\n",
    "\n",
    "class language_model:\n",
    "    \n",
    "    def __init__(self, ngram=1) :\n",
    "        self.ngram = ngram\n",
    "    \n",
    "    def train(self, text) :\n",
    "        \n",
    "        # Get sentences\n",
    "        sentences = self.get_sentences(text)\n",
    "        \n",
    "        # Get unigram frequency data\n",
    "        self.unigrams = Counter()\n",
    "        for s in sentences :\n",
    "            for w in s.split() :\n",
    "                self.unigrams[w] += 1\n",
    "        \n",
    "        if testing_mode :\n",
    "            print('Unigrams:')\n",
    "            for word, freq in self.unigrams.most_common(10) :\n",
    "                print(\"{}\\t{}\".format(word, freq))\n",
    "            print()\n",
    "            \n",
    "        # Get the number of total unigrams, and the total sum of their frequencies\n",
    "        self.V = len(self.unigrams)\n",
    "        self.total_count = sum(self.unigrams.values())\n",
    "        \n",
    "        # If we are using an ngram of 2 or more we need a frequency list of bigrams\n",
    "        if self.ngram > 1:\n",
    "            self.bigrams = Counter()\n",
    "            \n",
    "            for s in sentences :\n",
    "                words = s.split()\n",
    "                for i in range(len(words) - 1):\n",
    "                    self.bigrams[words[i] +' '+ words[i+1]] += 1\n",
    "                        \n",
    "            # Update V and total_count if we are using more than one gram\n",
    "            self.V = len(self.bigrams)\n",
    "            self.total_count = sum(self.bigrams.values())\n",
    "            \n",
    "            if testing_mode :\n",
    "                print('Bigrams:')\n",
    "                for word, freq in self.bigrams.most_common(10) :\n",
    "                    print(\"{}\\t\\t{}\".format(word, freq))\n",
    "                print()\n",
    "        \n",
    "        # If we are using an ngram of 3 or more we need a frequency list of trigrams\n",
    "        if self.ngram > 2:\n",
    "            self.trigrams = Counter()\n",
    "            \n",
    "            for s in sentences :\n",
    "                words = s.split()\n",
    "                for i in range(len(words) - 2):\n",
    "                    self.trigrams[words[i] +' '+ words[i+1] +' '+ words[i+2]] += 1\n",
    "            \n",
    "            # Update V and total_count if we are using more than one gram\n",
    "            self.V = len(self.trigrams)\n",
    "            self.total_count = sum(self.trigrams.values())\n",
    "            \n",
    "            if testing_mode :\n",
    "                print('Trigrams:')\n",
    "                for word, freq in self.trigrams.most_common(10) :\n",
    "                    print(\"{}\\t\\t\\t{}\".format(word, freq))\n",
    "                print()\n",
    "        \n",
    "        if testing_mode :\n",
    "            print('Number of ngrams:', self.V)\n",
    "            print('Total of ngram frequencies:', self.total_count)\n",
    "            print()\n",
    "    \n",
    "    def test(self, text) :\n",
    "        \n",
    "        # Get sentences\n",
    "        sentences = self.get_sentences(text)\n",
    "        \n",
    "        # Calculate sparsity\n",
    "        non_entries = 0\n",
    "        entries = 0\n",
    "        for s in sentences :\n",
    "            words = s.split()\n",
    "            for i in range(len(words) - (self.ngram - 1)) :\n",
    "                gram = ' '.join(words[i:i+self.ngram])\n",
    "                if self.count([gram]) :\n",
    "                    non_entries += 1\n",
    "                entries += 1\n",
    "        \n",
    "        self.sparsity = non_entries / entries\n",
    "        \n",
    "        return self.perplexity(sentences)\n",
    "    \n",
    "    def perplexity(self, sentences):\n",
    "        return math.pow(2, self.entropy(sentences))\n",
    "    \n",
    "    def entropy(self, sentences):\n",
    "        e = 0\n",
    "        offset = self.ngram - 1\n",
    "        length = 0\n",
    "        \n",
    "        for s in sentences :\n",
    "            words = s.split()\n",
    "            length += len(words)\n",
    "            for i in range(offset, len(words)) :\n",
    "                # context is the previous word/words for the bigram/trigram.\n",
    "                context = words[i - offset : i]\n",
    "                e += -math.log(self.probability(words[i], context), 2)  \n",
    "        return e / length\n",
    "    \n",
    "    def probability(self, word, context):\n",
    "        return (self.count(context + [word]) + 1) / (self.count(context) + self.V)\n",
    "    \n",
    "    def count(self, context):\n",
    "        size = len(context)\n",
    "        words = ' '.join(context)\n",
    "        \n",
    "        if size == 1: return self.unigrams.setdefault(words, 0)\n",
    "        if size == 2: return self.bigrams.setdefault(words, 0)\n",
    "        if size == 3: return self.trigrams.setdefault(words, 0)\n",
    "        \n",
    "        return 0\n",
    "    \n",
    "    def get_sentences(self, text):\n",
    "        \n",
    "        sentences = []\n",
    "        \n",
    "        lines = text.split('\\n')\n",
    "        \n",
    "        for l in lines :\n",
    "            # Convert to lower case.\n",
    "            l = l.lower()\n",
    "            \n",
    "            # Convert question marks (?), colons (:) and exclamation marks (!) to periods.\n",
    "            # Dashes should be converted to spaces.\n",
    "            # Remove all punctuation marks other than the period (commas, semicolons, underscores and quotes).\n",
    "            l = l.translate(str.maketrans('?:!-', '... ', string.punctuation.replace('.', '')))\n",
    "            \n",
    "            # Replace whitespace with a single space.\n",
    "            l = ' '.join(l.split())\n",
    "            \n",
    "            new_line = ''\n",
    "            for i in range(len(l)) :\n",
    "                if l[i] == '.' and i != len(l) - 1 and l[i+1] != ' ' :\n",
    "                    continue\n",
    "                else :\n",
    "                    new_line += l[i]\n",
    "            l = new_line\n",
    "            \n",
    "            # Parse the line into sentences, adding beginning-of-sentence and end-of-sentence tokens.\n",
    "            for s in l.split('.') :\n",
    "                s = s.strip()\n",
    "                if s :\n",
    "                    sentences.append('<s> '+ s +' </s>')\n",
    "        \n",
    "        return sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which N-gram is the most useful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following that, we ran the program through 3 different ngram models. This is to find the best ngram model by seeing which model provides a better cut off point for perplexity value, as that is what we will use to determine whether a title is clickbait or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def get_bins(num_bins, maximum, data) :\n",
    "    bins = [0]*num_bins\n",
    "    for p in data :\n",
    "        if p < maximum :\n",
    "            bins[int((p / maximum) * num_bins)] += 1\n",
    "    return bins\n",
    "\n",
    "# Graph shaping values:\n",
    "num_bins = 25\n",
    "width = 0.35\n",
    "\n",
    "for ngram in range(1, 4) :\n",
    "    nc_perps = []\n",
    "    c_perps = []\n",
    "    maximum = 0\n",
    "    \n",
    "    c_model = language_model(ngram)\n",
    "    c_model.train(open(argv[0], 'r').read())\n",
    "    for line in open(argv[1], 'r').readlines() :\n",
    "        line = line.strip()\n",
    "        if line :\n",
    "            perp = c_model.test(line)\n",
    "            c_perps.append(perp)\n",
    "            if perp > maximum :\n",
    "                maximum = perp\n",
    "\n",
    "    nc_model = language_model(ngram)\n",
    "    nc_model.train(open(argv[2], 'r').read())\n",
    "    for line in open(argv[3], 'r').readlines() :\n",
    "        line = line.strip()\n",
    "        if line :\n",
    "            perp = nc_model.test(line)\n",
    "            nc_perps.append(perp)\n",
    "            if perp > maximum :\n",
    "                maximum = perp\n",
    "        \n",
    "    nc_bins = get_bins(num_bins, maximum, nc_perps)\n",
    "    c_bins = get_bins(num_bins, maximum, c_perps)\n",
    "\n",
    "    ind = np.arange(num_bins)\n",
    "\n",
    "    plt.bar(ind, nc_bins, width, label='Non-clickbait')\n",
    "    plt.bar(ind+width, c_bins, width, label='Clickbait')\n",
    "\n",
    "    plt.xlabel('Perplexity')\n",
    "    plt.ylabel('# of articles')\n",
    "    title = 'Perplexity distribution of article headlines'\n",
    "    if ngram == 1 : plt.suptitle(title + ' (Unigrams)')\n",
    "    elif ngram == 2 : plt.suptitle(title + ' (Bigrams)')\n",
    "    elif ngram == 3 : plt.suptitle(title + ' (Trigrams)')\n",
    "    plt.legend(loc='best')\n",
    "\n",
    "    # You need to change xticks or else they will display 0 to num_bins\n",
    "    plt.xticks(ind + width / 2, (int(((i+1) / num_bins) * maximum) for i in range(num_bins)), rotation='vertical')\n",
    "    plt.subplots_adjust(bottom=0.2)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen above, it seems that the perplexity distribution graph for Bigrams looks the best (more bell-shaped curve). It can be noted that the Bigram really shows a cut off point for perplexity of what is and is not clickbait. But is using the Bigram model the most accurate?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating if it's clickbait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_ngram = 1\n",
    "\n",
    "clickbait_model = language_model(best_ngram)\n",
    "clickbait_model.train(open(argv[0], 'r').read())\n",
    "\n",
    "notclickbait_model = language_model(best_ngram)\n",
    "notclickbait_model.train(open(argv[2], 'r').read())\n",
    "\n",
    "def is_clickbait(article_headline) :\n",
    "    clickbait_perp = clickbait_model.test(article_headline)\n",
    "    notclickbait_perp = notclickbait_model.test(article_headline)\n",
    "    \n",
    "    if clickbait_perp < notclickbait_perp :\n",
    "        return True, 100*( 1-(clickbait_perp/(clickbait_perp+notclickbait_perp)) )\n",
    "    else :\n",
    "        return False, 100*( 1-(notclickbait_perp/(clickbait_perp+notclickbait_perp)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_ngram = 1\n",
    "\n",
    "clickbait_model = language_model(best_ngram)\n",
    "clickbait_model.train(open(argv[0], 'r').read())\n",
    "\n",
    "notclickbait_model = language_model(best_ngram)\n",
    "notclickbait_model.train(open(argv[2], 'r').read())\n",
    "\n",
    "def is_clickbait(article_headline) :\n",
    "    clickbait_perp = clickbait_model.test(article_headline)\n",
    "    notclickbait_perp = notclickbait_model.test(article_headline)\n",
    "    \n",
    "    if clickbait_perp < notclickbait_perp :\n",
    "        return True, 100*( 1-(clickbait_perp/(clickbait_perp+notclickbait_perp)) )\n",
    "    else :\n",
    "        return False, 100*( 1-(notclickbait_perp/(clickbait_perp+notclickbait_perp)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ngram: 1\n",
      "Clickbait accuracy: 99.84%\n",
      "Nonclickbait accuracy: 82.89%\n",
      "\n",
      "ngram: 2\n",
      "Clickbait accuracy: 99.75%\n",
      "Nonclickbait accuracy: 80.75%\n",
      "\n",
      "ngram: 3\n",
      "Clickbait accuracy: 99.16%\n",
      "Nonclickbait accuracy: 53.03%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for ngram in range(1, 4) :\n",
    "    print('ngram:', ngram)\n",
    "    \n",
    "    c_model = language_model(ngram)\n",
    "    c_model.train(open(argv[0], 'r').read())\n",
    "    \n",
    "    nc_model = language_model(ngram)\n",
    "    nc_model.train(open(argv[2], 'r').read())\n",
    "    \n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "    for line in open(argv[1], 'r').readlines() :\n",
    "        line = line.strip()\n",
    "        if line :\n",
    "            c_perp = c_model.test(line)\n",
    "            nc_perp = nc_model.test(line)\n",
    "            if c_perp < nc_perp :\n",
    "                correct += 1.0\n",
    "            total += 1.0\n",
    "    \n",
    "    c_accuracy = correct / total\n",
    "    print('Clickbait accuracy: {:.2f}%'.format(100.0*c_accuracy))\n",
    "    \n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "    for line in open(argv[3], 'r').readlines() :\n",
    "        line = line.strip()\n",
    "        if line :\n",
    "            c_perp = c_model.test(line)\n",
    "            nc_perp = nc_model.test(line)\n",
    "            if nc_perp < c_perp :\n",
    "                correct += 1.0\n",
    "            total += 1.0\n",
    "    \n",
    "    nc_accuracy = correct / total\n",
    "    print('Nonclickbait accuracy: {:.2f}%'.format(100.0*nc_accuracy))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown, it is clear that the Unigram is slightly more accurate with the accuracy of both clickbait and non-clickbait titles. \n",
    "\n",
    "### But....\n",
    "But don't just trust our results baselessly. Below is a code section that allows you to input a title and our code will determine whether it sounds like clikbait or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try it yourself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press \"stop\", \"quit\", or \"exit\" to stop\n",
      "\n",
      "Give me an article headline: The Tax Break for Children, Except the Ones Who Need It Most\n",
      "We are 72.93% sure it's clickbait\n",
      "\n",
      "Give me an article headline: As Protests Rage, Is India Moving Closer to Becoming a Hindu Nation?\n",
      "We are 53.56% sure it's not clickbait\n",
      "\n",
      "Give me an article headline: Purdue Pharma’s Payments to Sacklers Soared Amid Opioid Crisis\n",
      "We are 61.27% sure it's not clickbait\n",
      "\n",
      "Give me an article headline: How Mariah Carey’s ‘All I Want for Christmas Is You’ Finally Hit No. 1\n",
      "We are 75.25% sure it's clickbait\n",
      "\n",
      "Give me an article headline: Feral Pigs Roam the South. Now Even Northern States Aren’t Safe.\n",
      "We are 51.01% sure it's not clickbait\n",
      "\n",
      "Give me an article headline: stop\n"
     ]
    }
   ],
   "source": [
    "print(\"Press \\\"stop\\\", \\\"quit\\\", or \\\"exit\\\" to stop\", end='\\n\\n')\n",
    "\n",
    "while True :\n",
    "    article_headline = input('Give me an article headline: ').lower()\n",
    "    \n",
    "    if article_headline == 'stop' or article_headline == 'exit' or article_headline == 'quit' :\n",
    "        break\n",
    "    \n",
    "    is_cb, percentage = is_clickbait(article_headline)\n",
    "    \n",
    "    if is_cb :\n",
    "        print(\"We are {:.2f}% sure it's clickbait\".format(percentage))\n",
    "    else :\n",
    "        print(\"We are {:.2f}% sure it's not clickbait\".format(percentage))\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, it <b>is</b> possible to use a language model to classify/categorize something. I believe that the biggest problem using this methodology is finding the significant cutoff point of perplexity value for the category. Then again, this is under the consideration that we have already done the initial code/work before, thus making it easier. What is surprising, is though the Bigram model is considered the best model to work with based on a dataset of training, it appears that the Unigram model would be more accurate in determining the result."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
